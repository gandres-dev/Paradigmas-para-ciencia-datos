{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f823ae1d",
   "metadata": {},
   "source": [
    "# Escalamiento de características\n",
    "\n",
    "Este es otro paso clave en el preprocesamiento de datos; muchos algoritmos de aprendizaje y\n",
    "optimización tienen mejor comportamiento si las características discriminantes se encuentran en\n",
    "la misma escala.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cfd0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array([0,1,2,3,4,5])\n",
    "\n",
    "# Cambiamos de dimension a 2-D array, simulando que vino de un dataframe\n",
    "X_train = X_train.reshape(len(X_train), 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d7ef1a",
   "metadata": {},
   "source": [
    "Existen dos enfoques comunes para escalar características:\n",
    "\n",
    "- Normalización\n",
    "- Estandarización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a2510b",
   "metadata": {},
   "source": [
    "\n",
    "1.- **Normalización** , se refiere al reescalamiento de cada característica en el intervalo$[0, 1]$. Para esto, se aplica el escalamiento min-max en cada columna:\n",
    "\n",
    "\n",
    "$x_\\text{norm}^{(i)} = \\frac{x^{(i)} \\hspace{.3cm} - \\hspace{.3cm} x_\\text{min}}{x_\\text{max} \\hspace{.4cm} - \\hspace{.3cm}x_\\text{min}}$\n",
    "\n",
    "\n",
    "Donde $x^{(i)}$ es una muestra particular, $x_\\text{min}$ es el valor mínimo de la columna y $x_\\text{max}$ el\n",
    "máximo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70256d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizado: \n",
      " [[0. ]\n",
      " [0.2]\n",
      " [0.4]\n",
      " [0.6]\n",
      " [0.8]\n",
      " [1. ]]\n"
     ]
    }
   ],
   "source": [
    "X_train_norm = (X_train - X_train.min()) / (X_train.max() - X_train.min())\n",
    "print('Normalizado: \\n', X_train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac2415e",
   "metadata": {},
   "source": [
    "### Usando sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "33e02065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. ]\n",
      " [0.2]\n",
      " [0.4]\n",
      " [0.6]\n",
      " [0.8]\n",
      " [1. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train) # datos de entrenamiento\n",
    "#X_test_norm = mms . transform ( X_test ) # datos de prueba\n",
    "\n",
    "\n",
    "print(X_train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed03260",
   "metadata": {},
   "source": [
    "2.- **Estandarización**, este prepocesamiento puede resultar más práctico para algoritmos de optimización (p.e. _gradient descent_), esto se debe a que muchos modelos inicializan sus pesos a valores cercano a $0$. \n",
    "\n",
    "Utilizando estandarización, se centran las columnas de características a _media_ $0$ con _desvicion estándar_ $1$. Además, la estandarización mantiene información útil\n",
    "sobre secciones aisladas y hace que los algoritmos sean menos sensibles a ellas en contraste\n",
    "al escalamiento _min-max_.\n",
    "El procedimiento de estandarización se realiza con:\n",
    "\n",
    "\n",
    "\n",
    "$x_\\text{std}^{(i)} = \\frac{x^{(i)} \\hspace{.3cm} - \\hspace{.3cm} \\mu_x}{ \\sigma_x}$\n",
    "\n",
    "\n",
    "\n",
    "Donde $\\mu_x$ es la media muestral de una columna particular y $\\sigma_x$ es su correspondiente des-\n",
    "viación estándar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fadbcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estandarizado :\n",
      "  [[-1.46385011]\n",
      " [-0.87831007]\n",
      " [-0.29277002]\n",
      " [ 0.29277002]\n",
      " [ 0.87831007]\n",
      " [ 1.46385011]]\n"
     ]
    }
   ],
   "source": [
    "X_train_std = (X_train - X_train.mean()) / X_train.std()\n",
    "print('Estandarizado :\\n ', X_train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2f0536",
   "metadata": {},
   "source": [
    "### Usanso sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86a43df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.46385011]\n",
      " [-0.87831007]\n",
      " [-0.29277002]\n",
      " [ 0.29277002]\n",
      " [ 0.87831007]\n",
      " [ 1.46385011]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stds = StandardScaler()\n",
    "X_train_std = stds.fit_transform(X_train) # datos de entrenamiento\n",
    "#X_test_std = stds . transform ( X_test ) # datos de prueba\n",
    "\n",
    "print(X_train_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
